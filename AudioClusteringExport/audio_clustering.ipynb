{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9333dfd6-6606-4b09-9d34-ed612bccb987",
   "metadata": {},
   "source": [
    "# Audio Clustering - Export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60362858-2fcf-4900-b0ee-685d9bff8a71",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5768d3eb-4668-4520-bb72-61a2e5b42333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import torch\n",
    "import torchaudio\n",
    "import soundfile as sf\n",
    "import audio_analysis\n",
    "from matplotlib import pyplot as plt\n",
    "import wave\n",
    "import time\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import IPython\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2239b444-49b9-468f-bade-82f4fceb1d3b",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db437755-9bf5-4676-9603-eb16bbf2ca94",
   "metadata": {},
   "source": [
    "## Audio Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "578f4b46-d301-4502-9c00-ca949f4e2ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03787026e6024057a7d4ff1d2e395a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='../../Data/Audio/Gutenberg/', description='Audio File Path:', style=TextStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5248593a5e874ee999e2b1540fce94a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=48000, description='Audio Sample Rate:', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "783cd455fc3443119176ae63069795c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=1000, description='Audio Excerpt Length (milisec):', style=DescriptionStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df5df05e587b41719079f188c34deb57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=500, description='Audio Excerpt Offset (milisec):', style=DescriptionStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "audio_file_path = \"../../Data/Audio/Gutenberg/\"\n",
    "audio_file_extensions = [\"wav\", \"aiff\", \"aif\"] \n",
    "audio_sample_rate = 48000\n",
    "audio_excerpt_length = 1000 # in milisecs\n",
    "audio_excerpt_offset = 500 # in milisecs\n",
    "\n",
    "audio_feature_names = [\"root mean square\", \"mfcc\"]\n",
    "\n",
    "audio_file_path_gui = widgets.Text(value=audio_file_path, description=\"Audio File Path:\", style={'description_width': 'initial'}) \n",
    "audio_sample_rate_gui = widgets.IntText(value=audio_sample_rate, description=\"Audio Sample Rate:\", style={'description_width': 'initial'})\n",
    "audio_excerpt_length_gui = widgets.IntText(value=audio_excerpt_length, description=\"Audio Excerpt Length (milisec):\", style={'description_width': 'initial'})\n",
    "audio_excerpt_offset_gui = widgets.IntText(value=audio_excerpt_offset, description=\"Audio Excerpt Offset (milisec):\", style={'description_width': 'initial'})\n",
    "\n",
    "display(audio_file_path_gui)\n",
    "display(audio_sample_rate_gui)\n",
    "display(audio_excerpt_length_gui)\n",
    "display(audio_excerpt_offset_gui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab5e7164-e880-4602-8223-39a50d6f4611",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_path = audio_file_path_gui.value\n",
    "audio_sample_rate = audio_sample_rate_gui.value\n",
    "audio_excerpt_length = audio_excerpt_length_gui.value\n",
    "audio_excerpt_offset = audio_excerpt_offset_gui.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fc9806-e64e-4400-ac15-b4e1fafa13d9",
   "metadata": {},
   "source": [
    "## Cluster Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efa761ad-8581-486e-8c3a-c5f19852a607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab01631e849a4df394661b260ba8bf88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=100, description='Cluster Count:', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92520460f804c0990d504e12d0985da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=170, description='Cluster Random State:', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster_count = 100\n",
    "cluster_random_state = 170\n",
    "\n",
    "cluster_count_gui = widgets.IntText(value=cluster_count, description=\"Cluster Count:\", style={'description_width': 'initial'})\n",
    "cluster_random_state_gui = widgets.IntText(value=cluster_random_state, description=\"Cluster Random State:\", style={'description_width': 'initial'})\n",
    "\n",
    "display(cluster_count_gui)\n",
    "display(cluster_random_state_gui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e89220f-3dca-4a0f-a411-9db599457af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_count = cluster_count_gui.value\n",
    "cluster_random_state = cluster_random_state_gui.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56016015-a41f-439b-9cba-9da702cf98f5",
   "metadata": {},
   "source": [
    "## Load Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a816cd22-68f0-4ed1-aa26-859b6290e87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path  ../../Data/Audio/Gutenberg//Night_and_Day_by_Virginia_Woolf_48khz.wav\n",
      "waveform s  (162364604,)\n"
     ]
    }
   ],
   "source": [
    "audio_waveforms_full = []\n",
    "\n",
    "for root, _, fnames in sorted(os.walk(audio_file_path, followlinks=True)):\n",
    "    for fname in sorted(fnames):\n",
    "        \n",
    "        path = root + \"/\" + fname\n",
    "        \n",
    "        print(\"path \", path)\n",
    "        \n",
    "        audio_waveform, _ = librosa.load(path, sr=audio_sample_rate)\n",
    "\n",
    "        print(\"waveform s \", audio_waveform.shape)\n",
    "        \n",
    "        audio_waveforms_full.append(audio_waveform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674dd257-f236-4689-ada9-84ae537ae410",
   "metadata": {},
   "source": [
    "## Create Audio Excerpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc0befaa-325a-4f80-b47c-b83506b1f11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_excerpt_length_sc = int(audio_excerpt_length / 1000 * audio_sample_rate)\n",
    "audio_excerpt_offset_sc = int(audio_excerpt_offset / 1000 * audio_sample_rate)\n",
    "\n",
    "audio_waveform_excerpts = []\n",
    "\n",
    "for waveform_full in audio_waveforms_full:\n",
    "    waveform_sample_count = waveform_full.shape[0]\n",
    "    for sI in range(0, waveform_sample_count - audio_excerpt_length_sc, audio_excerpt_offset_sc):\n",
    "        waveform_except = waveform_full[sI:sI + audio_excerpt_length_sc]\n",
    "        audio_waveform_excerpts.append(waveform_except)\n",
    "        \n",
    "audio_waveforms = np.stack(audio_waveform_excerpts, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e034c71-7eff-4235-a8ea-d3ee3d3d7de0",
   "metadata": {},
   "source": [
    "## Calculate Audio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bd5b990-db4e-4a82-b3e9-9bd2a7507bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features = {}\n",
    "\n",
    "audio_features[\"waveform\"] = audio_waveforms\n",
    "if \"root mean square\" in audio_feature_names:\n",
    "    audio_features[\"root mean square\"] = audio_analysis.rms(audio_waveforms)\n",
    "if \"chroma stft\" in audio_feature_names:\n",
    "    audio_features[\"chroma stft\"] = audio_analysis.chroma_stft(audio_waveforms, audio_sample_rate)\n",
    "if \"chroma cqt\" in audio_feature_names:\n",
    "    audio_features[\"chroma cqt\"] = audio_analysis.chroma_cqt(audio_waveforms, audio_sample_rate)\n",
    "if \"chroma cens\" in audio_feature_names:\n",
    "    audio_features[\"chroma cens\"] = audio_analysis.chroma_cens(audio_waveforms, audio_sample_rate)\n",
    "if \"chroma vqt\" in audio_feature_names:\n",
    "    audio_features[\"chroma vqt\"] = audio_analysis.chroma_vqt(audio_waveforms, audio_sample_rate)\n",
    "if \"mel spectrogram\" in audio_feature_names:\n",
    "    audio_features[\"mel spectrogram\"] = audio_analysis.mel_spectrogram(audio_waveforms, audio_sample_rate)\n",
    "if \"mfcc\" in audio_feature_names:\n",
    "    audio_features[\"mfcc\"] = audio_analysis.mfcc(audio_waveforms, audio_sample_rate)\n",
    "if \"spectral centroid\" in audio_feature_names:\n",
    "    audio_features[\"spectral centroid\"] = audio_analysis.spectral_centroid(audio_waveforms, audio_sample_rate)\n",
    "if \"spectral bandwidth\" in audio_feature_names:\n",
    "    audio_features[\"spectral bandwidth\"] = audio_analysis.spectral_bandwidth(audio_waveforms, audio_sample_rate)\n",
    "if \"spectral contrast\" in audio_feature_names:\n",
    "    audio_features[\"spectral contrast\"] = audio_analysis.spectral_contrast(audio_waveforms, audio_sample_rate)\n",
    "if \"spectral flatness\" in audio_feature_names:\n",
    "    audio_features[\"spectral flatness\"] = audio_analysis.spectral_flatness(audio_waveforms)\n",
    "if \"spectral rolloff\" in audio_feature_names:\n",
    "    audio_features[\"spectral rolloff\"] = audio_analysis.spectral_rolloff(audio_waveforms, audio_sample_rate)\n",
    "if \"tempo\" in audio_feature_names:\n",
    "    audio_features[\"tempo\"] = audio_analysis.tempo(audio_waveforms, audio_sample_rate)\n",
    "if \"tempogram\" in audio_feature_names:\n",
    "    audio_features[\"tempogram\"] = audio_analysis.tempogram(audio_waveforms, audio_sample_rate)\n",
    "if \"tempogram ratio\" in audio_feature_names:\n",
    "    audio_features[\"tempogram ratio\"] = audio_analysis.tempogram_ratio(audio_waveforms, audio_sample_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68934ec0-33c0-4fa4-8b9c-c4d9d848665d",
   "metadata": {},
   "source": [
    "## Normalise Audio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "578bda0e-7c21-481f-ac3b-f2c1277e9b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for audio_feature_name in list(audio_features.keys()):\n",
    "    \n",
    "    #print(audio_feature_name)\n",
    "    \n",
    "    audio_feature = audio_features[audio_feature_name]\n",
    "    \n",
    "    audio_feature_mean = np.mean(audio_feature)\n",
    "    audio_feature_std = np.std(audio_feature)\n",
    "    \n",
    "    audio_feature_norm = (audio_feature - audio_feature_mean) / audio_feature_std\n",
    "    \n",
    "    #print(\"audio_feature_norm s \", audio_feature_norm.shape)\n",
    "\n",
    "    audio_features[audio_feature_name + \" norm\"] = audio_feature_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e344c1e-75ff-4649-96fe-7a9aff1c6d6a",
   "metadata": {},
   "source": [
    "## Combine Audio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59e82d40-550e-452c-a625-0e43a80ad9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features_proc = []\n",
    "for audio_feature_name in audio_feature_names:\n",
    "    audio_norm_feature_name = audio_feature_name + \" norm\"\n",
    "    audio_feature = audio_features[audio_norm_feature_name]\n",
    "    #print(\"name \", audio_norm_feature_name, \" shape \", audio_feature.shape)\n",
    "    audio_features_proc.append(audio_feature)\n",
    "    \n",
    "audio_features_proc = np.concatenate(audio_features_proc, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0b4e04-7cdd-49fc-acfb-eaa123857da7",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b14ba31b-f8d4-44dc-a45d-899153c1fa32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dbisig\\anaconda3\\envs\\ima2025\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=27.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "km = KMeans(n_clusters=cluster_count, n_init= \"auto\", random_state = cluster_random_state)\n",
    "labels =  km.fit_predict(audio_features_proc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c1c637-42db-4a23-8e0c-8962baa98f94",
   "metadata": {},
   "source": [
    "## Export Audio Files Per Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ba91948-78ac-4501-9b10-fffeff380dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_waveform_sc = audio_waveforms[0].shape[0]\n",
    "audio_amp_envelope = np.hanning(audio_waveform_sc)\n",
    "\n",
    "fileIndex = 0\n",
    "\n",
    "for excerpt_index, label in enumerate(labels):\n",
    "    cluster_index = label\n",
    "    audio_waveform = audio_waveforms[excerpt_index]\n",
    "\n",
    "    audio_file_name = \"data_proc/audio_cluster_{:05d}_excerpt_{:05d}_fcount_{:05d}.wav\".format(cluster_index, excerpt_index, fileIndex)\n",
    "    sf.write(audio_file_name, audio_waveform * audio_amp_envelope, audio_sample_rate)\n",
    "    \n",
    "    fileIndex += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
