{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cd66a5c-3855-469a-b167-8b8762f62c57",
   "metadata": {},
   "source": [
    "# Spectral Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c7b4e9-b07d-424a-91a4-e0802461c2ba",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d41c934-7a56-46b3-9a03-88b331dfa36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio as ta\n",
    "import sounddevice as sd\n",
    "import IPython\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dc170d-8199-4e71-a497-d910913dee6a",
   "metadata": {},
   "source": [
    "## Audio Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1cca6f-4c3a-4d2e-991f-45fbd284b1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_path = \"../../Data/Audio/Gutenberg/Night_and_Day_by_Virginia_Woolf_48khz.wav\"\n",
    "audio_sample_rate = 48000\n",
    "audio_range_sec = [ 10.0, 14.0 ]\n",
    "audio_output_device = 2\n",
    "audio_buffer_size = 512\n",
    "\n",
    "audio_file_gui = widgets.Text(value=audio_file_path, description=\"Audio File:\") \n",
    "audio_sample_rate_gui = widgets.IntText(value=audio_sample_rate, description=\"Audio Sample Rate:\")\n",
    "audio_range_sec_gui_1 = widgets.IntText(value=audio_range_sec[0], description=\"Audio Range Start (sec):\", style={'description_width': 'initial'})\n",
    "audio_range_sec_gui_2 = widgets.IntText(value=audio_range_sec[1], description=\"Audio Range End (sec):\", style={'description_width': 'initial'})\n",
    "audio_output_device_gui = widgets.IntText(value=audio_output_device, description=\"Audio Output Device:\", style={'description_width': 'initial'})\n",
    "audio_buffer_size_gui = widgets.IntText(value=audio_buffer_size, description=\"Audio Buffer Size:\", style={'description_width': 'initial'})\n",
    "\n",
    "display(audio_file_gui)\n",
    "display(audio_sample_rate_gui)\n",
    "display(audio_range_sec_gui_1)\n",
    "display(audio_range_sec_gui_2)\n",
    "print(sd.query_devices())\n",
    "display(audio_output_device_gui)\n",
    "display(audio_buffer_size_gui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c6db35-b6df-4a09-960c-3b42495540ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_path = audio_file_gui.value\n",
    "audio_sample_rate = audio_sample_rate_gui.value\n",
    "audio_range_sec[0] = audio_range_sec_gui_1.value\n",
    "audio_range_sec[1] = audio_range_sec_gui_2.value\n",
    "audio_output_device = audio_output_device_gui.value\n",
    "audio_buffer_size = audio_buffer_size_gui.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ff48e9-4aed-45fb-8d70-d5337d2a14ab",
   "metadata": {},
   "source": [
    "## Load Audio File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51786c99-a279-4465-83ab-2c0de389a2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_waveform, _ = ta.load(audio_file_path)\n",
    "audio_waveform = audio_waveform[:, int(audio_range_sec[0] * audio_sample_rate) : int(audio_range_sec[1] * audio_sample_rate) ]\n",
    "\n",
    "audio_channel_count = audio_waveform.shape[0]\n",
    "audio_sample_count = audio_waveform.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7b0dc3-8375-4722-9efd-7de3b45954c9",
   "metadata": {},
   "source": [
    "## Create Audio Playback Buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6832d6b-e76e-4565-bec7-758016210bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_window = torch.from_numpy(np.hanning(audio_buffer_size))\n",
    "audio_ring_buffer = torch.zeros((audio_buffer_size * 2), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc253ef6-0c09-4068-bb64-65030358223b",
   "metadata": {},
   "source": [
    "## Real-Time Audio - Regular Windowed Audio Playback "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d39ff1-83ae-4610-b4ab-5d0e55ef5c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_sample_index = 0\n",
    "\n",
    "def audio_callback(out_data, frame_count, time_info, status):\n",
    "\n",
    "    global audio_ring_buffer\n",
    "    global audio_sample_index\n",
    "    \n",
    "    for i in range(2):\n",
    "        \n",
    "        audio_buffer = audio_waveform[0, audio_sample_index:audio_sample_index + audio_buffer_size]\n",
    "        \n",
    "        audio_ring_buffer = torch.roll(audio_ring_buffer, -audio_buffer_size // 2)\n",
    "        audio_ring_buffer[-audio_buffer_size//2:] = 0.0\n",
    "        audio_ring_buffer[-audio_buffer_size:] += audio_buffer * audio_window\n",
    "        \n",
    "        audio_sample_index += audio_buffer_size // 2\n",
    "        \n",
    "        # loop\n",
    "        if audio_sample_index >= audio_sample_count - audio_buffer_size:\n",
    "            audio_sample_index = 0\n",
    "            \n",
    "    out_data[:, 0] = audio_ring_buffer[:audio_buffer_size]\n",
    "\n",
    "audio_stream = sd.OutputStream(\n",
    "    samplerate=audio_sample_rate, blocksize=audio_buffer_size, device=audio_output_device, channels=audio_channel_count,\n",
    "    callback=audio_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f67542-ebd1-4a4e-bd9a-19ba5a6e1076",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_stream.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1913159c-28c4-4cd5-99da-65e6a73c8561",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_stream.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661a14ba-b62b-4ff3-838e-850b54eb1ebc",
   "metadata": {},
   "source": [
    "## Real-Time Audio - FFT and IFFT Audio Playback "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059370e0-c3c7-4974-9f4d-347c8421c536",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_sample_index = 0\n",
    "\n",
    "# regular fft and ifft\n",
    "def audio_callback(out_data, frame_count, time_info, status):\n",
    "    \n",
    "    global audio_ring_buffer\n",
    "    global audio_sample_index\n",
    "    \n",
    "    for i in range(2):\n",
    "        \n",
    "        audio_buffer = audio_waveform[0, audio_sample_index:audio_sample_index + audio_buffer_size]\n",
    "        audio_buffer_windowed = audio_buffer * audio_window\n",
    "    \n",
    "        audio_spectrum = torch.fft.fft(audio_buffer_windowed.reshape(1, -1))\n",
    "        audio_buffer_rec = torch.fft.ifft(audio_spectrum)[0].real\n",
    "        \n",
    "        audio_ring_buffer = torch.roll(audio_ring_buffer, -audio_buffer_size // 2)\n",
    "        audio_ring_buffer[-audio_buffer_size//2:] = 0.0\n",
    "        audio_ring_buffer[-audio_buffer_size:] += audio_buffer_rec\n",
    "        \n",
    "        audio_sample_index += audio_buffer_size // 2\n",
    "        \n",
    "        # loop\n",
    "        if audio_sample_index >= audio_sample_count - audio_buffer_size:\n",
    "            audio_sample_index = 0\n",
    "            \n",
    "    out_data[:, 0] = audio_ring_buffer[:audio_buffer_size]\n",
    "\n",
    "audio_stream = sd.OutputStream(\n",
    "    samplerate=audio_sample_rate, blocksize=audio_buffer_size, device=audio_output_device, channels=audio_channel_count,\n",
    "    callback=audio_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aa54ed-fe52-4d8f-987b-4a74227c0690",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_stream.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84def36e-e50c-4f27-9393-c849c8941714",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_stream.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c577846-962a-4f10-8c2a-35c8adc0cd87",
   "metadata": {},
   "source": [
    "## Real-Time Audio - FFT and IFFT Audio Playback (with an additional conversion from complex values to polar coordinates and back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5984722e-dc13-406a-9981-6f89cc1ac812",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_sample_index = 0\n",
    "\n",
    "# regular fft and ifft (with an additional conversion from complex values to polar coordinates and back)\n",
    "def audio_callback(out_data, frame_count, time_info, status):\n",
    "    \n",
    "    global audio_ring_buffer\n",
    "    global audio_sample_index\n",
    "    \n",
    "    for i in range(2):\n",
    "        \n",
    "        audio_buffer = audio_waveform[0, audio_sample_index:audio_sample_index + audio_buffer_size]\n",
    "        audio_buffer_windowed = audio_buffer * audio_window\n",
    "    \n",
    "        audio_spectrum = torch.fft.fft(audio_buffer_windowed.reshape(1, -1))\n",
    "        audio_spectrum_mag = audio_spectrum.abs()\n",
    "        audio_spectrum_phase = audio_spectrum.angle()\n",
    "        audio_spectrum2 = torch.polar(audio_spectrum_mag, audio_spectrum_phase)\n",
    "        \n",
    "        audio_buffer_rec = torch.fft.ifft(audio_spectrum2)[0].real\n",
    "        \n",
    "        audio_ring_buffer = torch.roll(audio_ring_buffer, -audio_buffer_size // 2)\n",
    "        audio_ring_buffer[-audio_buffer_size//2:] = 0.0\n",
    "        audio_ring_buffer[-audio_buffer_size:] += audio_buffer_rec\n",
    "        \n",
    "        audio_sample_index += audio_buffer_size // 2\n",
    "        \n",
    "        # loop\n",
    "        if audio_sample_index >= audio_sample_count - audio_buffer_size:\n",
    "            audio_sample_index = 0\n",
    "            \n",
    "    out_data[:, 0] = audio_ring_buffer[:audio_buffer_size]\n",
    "\n",
    "audio_stream = sd.OutputStream(\n",
    "    samplerate=audio_sample_rate, blocksize=audio_buffer_size, device=audio_output_device, channels=audio_channel_count,\n",
    "    callback=audio_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c27fd6-a307-45d2-9022-21b6d2978d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_stream.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758bb395-e003-4362-b77a-053454a89d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_stream.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dab2dcc-4dda-45dd-8dbe-c874d86e8961",
   "metadata": {},
   "source": [
    "## Real-Time Audio - Audio Playback with Magnitude Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e223d18-06f6-461c-9651-677eb9bef6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_threshold = 10.0\n",
    "audio_sample_index = 0\n",
    "\n",
    "# discard phase information\n",
    "def audio_callback(out_data, frame_count, time_info, status):\n",
    "    \n",
    "    global audio_ring_buffer\n",
    "    global audio_sample_index\n",
    "    \n",
    "    for i in range(2):\n",
    "        \n",
    "        audio_buffer = audio_waveform[0, audio_sample_index:audio_sample_index + audio_buffer_size]\n",
    "        audio_buffer_windowed = audio_buffer * audio_window\n",
    "    \n",
    "        audio_spectrum = torch.fft.fft(audio_buffer_windowed.reshape(1, -1))\n",
    "        audio_spectrum_mag = audio_spectrum.abs()\n",
    "        audio_spectrum_mag[torch.logical_and(audio_spectrum_mag>=0, audio_spectrum_mag<=mag_threshold)] = 0.0\n",
    "        audio_spectrum_phase = audio_spectrum.angle()\n",
    "        audio_spectrum2 = torch.polar(audio_spectrum_mag, audio_spectrum_phase)\n",
    "\n",
    "        audio_buffer_rec = torch.fft.ifft(audio_spectrum2)[0].real\n",
    "        \n",
    "        audio_ring_buffer = torch.roll(audio_ring_buffer, -audio_buffer_size // 2)\n",
    "        audio_ring_buffer[-audio_buffer_size//2:] = 0.0\n",
    "        audio_ring_buffer[-audio_buffer_size:] += audio_buffer_rec\n",
    "        \n",
    "        audio_sample_index += audio_buffer_size // 2\n",
    "        \n",
    "        # loop\n",
    "        if audio_sample_index >= audio_sample_count - audio_buffer_size:\n",
    "            audio_sample_index = 0\n",
    "            \n",
    "    out_data[:, 0] = audio_ring_buffer[:audio_buffer_size]\n",
    "\n",
    "audio_stream = sd.OutputStream(\n",
    "    samplerate=audio_sample_rate, blocksize=audio_buffer_size, device=audio_output_device, channels=audio_channel_count,\n",
    "    callback=audio_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e7ee48-02bb-4190-a7e1-ac6c76f21f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_stream.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c655ff5b-0b7a-4380-bc63-7983ac34dfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_threshold_gui = widgets.FloatText(value=mag_threshold, description=\"Magnitude Threshold:\", style={'description_width': 'initial'})\n",
    "\n",
    "display(mag_threshold_gui)\n",
    "\n",
    "def on_mag_threshold_change(value):\n",
    "    global mag_threshold\n",
    "    mag_threshold = value['new']\n",
    "\n",
    "mag_threshold_gui.observe(on_mag_threshold_change, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958a32a9-7dc1-4b58-9e12-943d48e50279",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_stream.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0a83c7-e773-4631-9faa-6065141460cd",
   "metadata": {},
   "source": [
    "## Real-Time Audio - Discard Phase Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ccc546-6aae-446e-8f73-94651a753e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_sample_index = 0\n",
    "\n",
    "# discard phase information\n",
    "def audio_callback(out_data, frame_count, time_info, status):\n",
    "    \n",
    "    global audio_ring_buffer\n",
    "    global audio_sample_index\n",
    "    \n",
    "    for i in range(2):\n",
    "        \n",
    "        audio_buffer = audio_waveform[0, audio_sample_index:audio_sample_index + audio_buffer_size]\n",
    "        audio_buffer_windowed = audio_buffer * audio_window\n",
    "    \n",
    "        audio_spectrum = torch.fft.fft(audio_buffer_windowed.reshape(1, -1))\n",
    "        audio_spectrum_mag = audio_spectrum.abs()\n",
    "        audio_spectrum_phase = torch.zeros_like(audio_spectrum.angle())\n",
    "        audio_spectrum2 = torch.polar(audio_spectrum_mag, audio_spectrum_phase)\n",
    "\n",
    "        audio_buffer_rec = torch.fft.ifft(audio_spectrum2)[0].real\n",
    "        \n",
    "        audio_ring_buffer = torch.roll(audio_ring_buffer, -audio_buffer_size // 2)\n",
    "        audio_ring_buffer[-audio_buffer_size//2:] = 0.0\n",
    "        audio_ring_buffer[-audio_buffer_size:] += audio_buffer_rec\n",
    "        \n",
    "        audio_sample_index += audio_buffer_size // 2\n",
    "        \n",
    "        # loop\n",
    "        if audio_sample_index >= audio_sample_count - audio_buffer_size:\n",
    "            audio_sample_index = 0\n",
    "            \n",
    "    out_data[:, 0] = audio_ring_buffer[:audio_buffer_size]\n",
    "\n",
    "audio_stream = sd.OutputStream(\n",
    "    samplerate=audio_sample_rate, blocksize=audio_buffer_size, device=audio_output_device, channels=audio_channel_count,\n",
    "    callback=audio_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7947149-de41-425a-83d8-3c49fce56292",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_stream.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9610db8-23d3-44be-a6c3-5e35d0590745",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_stream.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31f9431-79e2-4f33-9674-56caf1916e1e",
   "metadata": {},
   "source": [
    "## Real-Time Audio - Swap Frequency Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3898844-4d27-45e9-a1f5-7c2992760e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "freq_bin_remap = rng.choice(audio_buffer_size//2, size=audio_buffer_size//2, replace=False)\n",
    "freq_bin_remap = np.concatenate((freq_bin_remap, freq_bin_remap[::-1]))\n",
    "\n",
    "audio_sample_index = 0\n",
    "\n",
    "def audio_callback(out_data, frame_count, time_info, status):\n",
    "    \n",
    "    global audio_ring_buffer\n",
    "    global audio_sample_index\n",
    "    \n",
    "    for i in range(2):\n",
    "        \n",
    "        audio_buffer = audio_waveform[0, audio_sample_index:audio_sample_index + audio_buffer_size]\n",
    "        audio_buffer_windowed = audio_buffer * audio_window\n",
    "    \n",
    "        audio_spectrum = torch.fft.fft(audio_buffer_windowed.reshape(1, -1))\n",
    "        audio_spectrum2 = audio_spectrum[:, freq_bin_remap]\n",
    "\n",
    "        audio_buffer_rec = torch.fft.ifft(audio_spectrum2)[0].real\n",
    "        \n",
    "        audio_ring_buffer = torch.roll(audio_ring_buffer, -audio_buffer_size // 2)\n",
    "        audio_ring_buffer[-audio_buffer_size//2:] = 0.0\n",
    "        audio_ring_buffer[-audio_buffer_size:] += audio_buffer_rec\n",
    "        \n",
    "        audio_sample_index += audio_buffer_size // 2\n",
    "        \n",
    "        # loop\n",
    "        if audio_sample_index >= audio_sample_count - audio_buffer_size:\n",
    "            audio_sample_index = 0\n",
    "            \n",
    "    out_data[:, 0] = audio_ring_buffer[:audio_buffer_size]\n",
    "\n",
    "audio_stream = sd.OutputStream(\n",
    "    samplerate=audio_sample_rate, blocksize=audio_buffer_size, device=audio_output_device, channels=audio_channel_count,\n",
    "    callback=audio_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c1136f-f575-41f4-a326-3bb5c887f066",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_stream.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607fbb09-8651-48ec-b9d1-fa9e027dc1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_stream.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b5a0b6-4b7c-46d9-95ba-122361652b65",
   "metadata": {},
   "source": [
    "## Real-Time Audio - Freeze Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f56d9c6-ae58-423b-8d82-58579c6f8fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_spectrum = None\n",
    "audio_spectrum_freeze_factor = 0.98\n",
    "audio_sample_index = 0\n",
    "\n",
    "def audio_callback(out_data, frame_count, time_info, status):\n",
    "    \n",
    "    global audio_ring_buffer\n",
    "    global audio_sample_index\n",
    "    global audio_spectrum\n",
    "    \n",
    "    for i in range(2):\n",
    "        \n",
    "        audio_buffer = audio_waveform[0, audio_sample_index:audio_sample_index + audio_buffer_size]\n",
    "        audio_buffer_windowed = audio_buffer * audio_window\n",
    "    \n",
    "        new_audio_spectrum = torch.fft.fft(audio_buffer_windowed.reshape(1, -1))\n",
    "        \n",
    "        if audio_spectrum is None:\n",
    "            audio_spectrum = new_audio_spectrum\n",
    "        else:\n",
    "            old_audio_spectrum_mag = audio_spectrum.abs()\n",
    "            new_audio_spectrum_mag = new_audio_spectrum.abs()\n",
    "            new_audio_spectrum_phase = new_audio_spectrum.angle()\n",
    "            \n",
    "            audio_spectrum_mag = old_audio_spectrum_mag * audio_spectrum_freeze_factor + new_audio_spectrum_mag * (1.0 - audio_spectrum_freeze_factor)\n",
    "\n",
    "            audio_spectrum = torch.polar(audio_spectrum_mag, new_audio_spectrum_phase)\n",
    "\n",
    "        audio_buffer_rec = torch.fft.ifft(audio_spectrum)[0].real\n",
    "        \n",
    "        audio_ring_buffer = torch.roll(audio_ring_buffer, -audio_buffer_size // 2)\n",
    "        audio_ring_buffer[-audio_buffer_size//2:] = 0.0\n",
    "        audio_ring_buffer[-audio_buffer_size:] += audio_buffer_rec\n",
    "        \n",
    "        audio_sample_index += audio_buffer_size // 2\n",
    "        \n",
    "        # loop\n",
    "        if audio_sample_index >= audio_sample_count - audio_buffer_size:\n",
    "            audio_sample_index = 0\n",
    "            \n",
    "    out_data[:, 0] = audio_ring_buffer[:audio_buffer_size]\n",
    "\n",
    "\n",
    "audio_stream = sd.OutputStream(\n",
    "    samplerate=audio_sample_rate, blocksize=audio_buffer_size, device=audio_output_device, channels=audio_channel_count,\n",
    "    callback=audio_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fc97c0-e03b-49a6-a4b0-d3b3109ce7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_stream.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1638e1-ba9b-4fdd-81f6-e43ff4e1a816",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_spectrum_freeze_factor_gui = widgets.FloatText(value=audio_spectrum_freeze_factor, description=\"Audio Spectrum Freeze Factor:\", style={'description_width': 'initial'})\n",
    "\n",
    "display(audio_spectrum_freeze_factor_gui)\n",
    "\n",
    "def on_freeze_factor_change(value):\n",
    "    global audio_spectrum_freeze_factor\n",
    "    audio_spectrum_freeze_factor = value['new']\n",
    "\n",
    "audio_spectrum_freeze_factor_gui.observe(on_freeze_factor_change, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179d9039-af12-4dfa-8461-aa6ae8bdce14",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_stream.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
