{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aafb3e65-3228-4383-a1e9-6fd01c006c38",
   "metadata": {},
   "source": [
    "# Motion Continuation LSTM (Inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a8445f-c23e-4cee-ad61-fdb6777a9cf4",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4830874a-d591-4f9f-9c41-a4e26eb967b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as nnF\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchaudio\n",
    "import torchaudio.transforms as transforms\n",
    "from collections import OrderedDict\n",
    "\n",
    "from vocos import Vocos\n",
    "\n",
    "import IPython\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4673fd7-4173-4c89-a701-4498ecbdf54e",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb3f079-4136-4e5d-b1fd-7b4a67738ce6",
   "metadata": {},
   "source": [
    "### Compute Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4df04a9-b709-4338-be6e-dfe2d3c95716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88779f7e-88ed-426c-800b-1f34a8afbd84",
   "metadata": {},
   "source": [
    "### Audio Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b833f1e-94bd-4b4c-9480-09b100781862",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_sample_rate = 48000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b25c5b-8c76-4645-a268-9783652be153",
   "metadata": {},
   "source": [
    "### Model Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deb7a52a-cb42-4e1f-b4b4-53398ef906a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d833e6a13fec45bc944533e2abe869e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=2, description='LSTM Layer Count:', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "583ba0ad2ca549468d4a0674f6610911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=512, description='LSTM Layer Dim:', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116b1f3a4bbc49bda3245febe569c256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='../../../../Data/Models/AudioContinuation/RNN/Gutenberg/weights/rnn_weights_epoch_200', descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnn_layer_dim = 512\n",
    "rnn_layer_count = 2\n",
    "\n",
    "rnn_weights_file = \"../../../../Data/Models/AudioContinuation/RNN/Gutenberg/weights/rnn_weights_epoch_200\"\n",
    "\n",
    "rnn_layer_count_gui = widgets.IntText(value=rnn_layer_count, description=\"LSTM Layer Count:\", style={'description_width': 'initial'})\n",
    "rnn_layer_dim_gui = widgets.IntText(value=rnn_layer_dim, description=\"LSTM Layer Dim:\", style={'description_width': 'initial'})\n",
    "\n",
    "rnn_weights_file_gui = widgets.Text(value=rnn_weights_file, description=\"RNN Weights File:\", style={'description_width': 'initial'}) \n",
    "\n",
    "display(rnn_layer_count_gui)\n",
    "display(rnn_layer_dim_gui)\n",
    "display(rnn_weights_file_gui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c85cedf5-9dbb-4323-8bfb-560b78dce2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_layer_count = rnn_layer_count_gui.value\n",
    "rnn_layer_dim = rnn_layer_dim_gui.value\n",
    "rnn_weights_file = rnn_weights_file_gui.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f98119-462b-4425-b022-b14942f3d9b4",
   "metadata": {},
   "source": [
    "### Training settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f4d472f-e050-4605-8c23-0c042f5be296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3544b804ebc419da8d947aa4a484783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=64, description='Sequence Input Length:', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_input_length = 64\n",
    "\n",
    "seq_input_length_gui = widgets.IntText(value=seq_input_length, description=\"Sequence Input Length:\", style={'description_width': 'initial'})\n",
    "\n",
    "display(seq_input_length_gui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ce371bb-7f82-4ac1-8793-6e377e530809",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_input_length = seq_input_length_gui.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a1b19d-53ab-45c5-a255-6ca2b9f6079b",
   "metadata": {},
   "source": [
    "## Load Vocos Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92ac8933-53cf-4502-a168-9459789d049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocos = Vocos.from_pretrained(\"kittn/vocos-mel-48khz-alpha1\")\n",
    "\n",
    "dummy_waveform = torch.zeros((1, audio_sample_rate), dtype=torch.float32).to(device)\n",
    "dummy_mels = vocos.feature_extractor(dummy_waveform)\n",
    "\n",
    "audio_features_dim = dummy_mels.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da9f4be-5e94-4910-8ed2-f4e1deebc863",
   "metadata": {},
   "source": [
    "## Create Recurrent Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebb5aff6-655c-4be6-a99a-46768c3755f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reccurent(\n",
      "  (rnn_layers): Sequential(\n",
      "    (rnn): LSTM(128, 512, num_layers=2, batch_first=True)\n",
      "  )\n",
      "  (dense_layers): Sequential(\n",
      "    (dense): Linear(in_features=512, out_features=128, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Reccurent(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, layer_count):\n",
    "        super(Reccurent, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_count = layer_count\n",
    "        self.output_dim = output_dim\n",
    "            \n",
    "        rnn_layers = []\n",
    "        \n",
    "        rnn_layers.append((\"rnn\", nn.LSTM(self.input_dim, self.hidden_dim, self.layer_count, batch_first=True)))\n",
    "        self.rnn_layers = nn.Sequential(OrderedDict(rnn_layers))\n",
    "        \n",
    "        dense_layers = []\n",
    "        dense_layers.append((\"dense\", nn.Linear(self.hidden_dim, self.output_dim)))\n",
    "        self.dense_layers = nn.Sequential(OrderedDict(dense_layers))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x, (_, _) = self.rnn_layers(x)\n",
    "        \n",
    "        x = x[:, -1, :] # only last time step \n",
    "        x = self.dense_layers(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "rnn = Reccurent(audio_features_dim, rnn_layer_dim, audio_features_dim, rnn_layer_count).to(device)\n",
    "\n",
    "print(rnn)\n",
    "\n",
    "if device == 'cuda':\n",
    "    rnn.load_state_dict(torch.load(rnn_weights_file))\n",
    "else:\n",
    "    rnn.load_state_dict(torch.load(rnn_weights_file, map_location=device ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e341fa-c0bc-42eb-9068-cd0be7ab84a5",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd037226-93c5-400e-9cc3-391e8526f746",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.eval()\n",
    "\n",
    "def export_orig_audio(waveform_data, start_time, end_time, file_name):\n",
    "    \n",
    "    start_time_samples = int(start_time * audio_sample_rate)\n",
    "    end_time_samples = int(end_time * audio_sample_rate)\n",
    "    \n",
    "    torchaudio.save(file_name, waveform_data[:, start_time_samples:end_time_samples], audio_sample_rate)\n",
    "\n",
    "def export_ref_audio(waveform_data, start_time, end_time, file_name):\n",
    "    \n",
    "    start_time_samples = int(start_time * audio_sample_rate)\n",
    "    end_time_samples = int(end_time * audio_sample_rate)\n",
    "    \n",
    "    # audio features\n",
    "    audio_features = vocos.feature_extractor(waveform_data[:, start_time_samples:end_time_samples])\n",
    "    \n",
    "    ref_audio = vocos.decode(audio_features)\n",
    "    \n",
    "    torchaudio.save(file_name, ref_audio.detach().cpu(), audio_sample_rate)\n",
    "    \n",
    "def export_pred_audio(waveform_data, start_time, end_time, file_name):\n",
    "    \n",
    "    start_time_samples = int(start_time * audio_sample_rate)\n",
    "    end_time_samples = int(end_time * audio_sample_rate)\n",
    "    \n",
    "    # audio features\n",
    "    audio_features = vocos.feature_extractor(waveform_data[:, start_time_samples:end_time_samples])\n",
    "    \n",
    "    #print(\"audio_features s \", audio_features.shape)\n",
    "    \n",
    "    audio_features = audio_features.squeeze(0)\n",
    "    audio_features = torch.permute(audio_features, (1, 0))\n",
    "    audio_feature_count = audio_features.shape[0]\n",
    "    \n",
    "    #print(\"audio_feature_count \", audio_feature_count)\n",
    "    \n",
    "    input_features = audio_features[:seq_input_length]\n",
    "    input_features = input_features.unsqueeze(0)\n",
    "    \n",
    "    output_features_length = audio_feature_count - seq_input_length\n",
    "    \n",
    "    #print(\"output_features_length \", output_features_length)\n",
    "    \n",
    "    _input_features = input_features  \n",
    "    pred_features = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for o_i in range(1, output_features_length):\n",
    "            \n",
    "            _input_features = _input_features.to(device)\n",
    "            \n",
    "            #print(\"_input_features s \", _input_features.shape)\n",
    "            \n",
    "            _pred_features = rnn(_input_features)\n",
    "            _pred_features = torch.unsqueeze(_pred_features, axis=1)\n",
    "\n",
    "            _input_features = _input_features[:, 1:, :].detach().clone()\n",
    "            _pred_features = _pred_features.detach().clone()\n",
    "            \n",
    "            pred_features.append(_pred_features.cpu())\n",
    "            \n",
    "            _input_features = torch.cat((_input_features, _pred_features), axis=1)\n",
    "                \n",
    "            #print(\"_input_features s \", _input_features.shape)\n",
    "            \n",
    "    pred_features = torch.cat(pred_features, axis=1)\n",
    "    pred_features = torch.permute(pred_features, (0, 2, 1))\n",
    "    pred_audio = vocos.decode(pred_features)\n",
    "    \n",
    "    torchaudio.save(file_name, pred_audio.detach().cpu(), audio_sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de7b5ef-f964-4535-87aa-0701457bb9b6",
   "metadata": {},
   "source": [
    "### Perform Audio Continuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77daf847-a477-4e0d-b882-3a4ed7f16495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36f27f845a7d4f8bbd2929ca95a12e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='../../../../Data/Audio/Gutenberg/Night_and_Day_by_Virginia_Woolf_48khz.wav', description='Audio Fi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43b5a5e63c714bc492fe048ce1b57a6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=60.0, description='Audio Start Time [Seconds]:', style=DescriptionStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a030c9541a4d4986bb91f9c72af3b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=80.0, description='Audio End Time [Seconds]', style=DescriptionStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "audio_file = \"../../../../Data/Audio/Gutenberg/Night_and_Day_by_Virginia_Woolf_48khz.wav\"\n",
    "audio_start_time_sec = 60.0\n",
    "audio_end_time_sec = 80.0\n",
    "\n",
    "audio_file_gui = widgets.Text(value=audio_file, description=\"Audio File:\", style={'description_width': 'initial'})\n",
    "audio_start_time_sec_gui = widgets.FloatText(value=audio_start_time_sec, description=\"Audio Start Time [Seconds]:\", style={'description_width': 'initial'})\n",
    "audio_end_time_sec_gui = widgets.FloatText(value=audio_end_time_sec, description=\"Audio End Time [Seconds]\", style={'description_width': 'initial'})\n",
    "\n",
    "display(audio_file_gui)\n",
    "display(audio_start_time_sec_gui)\n",
    "display(audio_end_time_sec_gui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d8a9eda-d8d4-46aa-bf9f-2a91fced684f",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = audio_file_gui.value\n",
    "audio_start_time_sec = audio_start_time_sec_gui.value\n",
    "audio_end_time_sec = audio_end_time_sec_gui.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3151496b-3b7d-404d-b992-cf25b381885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform_data, _ = torchaudio.load(audio_file)\n",
    "\n",
    "export_orig_audio(waveform_data, audio_start_time_sec, audio_end_time_sec, \"results/audio/orig_{}-{}.wav\".format(audio_start_time_sec, audio_end_time_sec))\n",
    "export_ref_audio(waveform_data, audio_start_time_sec, audio_end_time_sec, \"results/audio/ref_{}-{}.wav\".format(audio_start_time_sec, audio_end_time_sec))\n",
    "export_pred_audio(waveform_data, audio_start_time_sec, audio_end_time_sec, \"results/audio/pred_{}-{}.wav\".format(audio_start_time_sec, audio_end_time_sec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed7e617-8397-4be4-8c37-be51bdc5b13e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
